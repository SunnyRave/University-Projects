# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KxmmjSHhZ_Vbl3zYVnGjPWZ7Ook4grFk
"""

# Zid - z5436640
# Name - Sunit Ravi
import numpy as np
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.optimizers import SGD
from sklearn.metrics import mean_squared_error
from math import sqrt

# Inputs and targets
compoundA = np.loadtxt('compoundA.txt')
substrate = np.loadtxt('substrate.txt')
t = np.loadtxt('biomass.txt')
# Check and replace negative values in substrate and compoundA
substrate[substrate < 0] = 0
compoundA[compoundA < 0] = 0
# Normalization
compoundA = (compoundA - np.min(compoundA)) / (np.max(compoundA) - np.min(compoundA))
substrate = (substrate - np.min(substrate)) / (np.max(substrate) - np.min(substrate))



# Check and replace negative values in t
t[t < 0] = 0

t = (t - np.min(t)) / (np.max(t) - np.min(t))

# Calculate the index where to split
split = int(len(substrate) * 0.7)

# Split substrate array
substrate_train = substrate[:split]
substrate_test = substrate[split:]

# Split compoundA array
compoundA_train = compoundA[:split]
compoundA_test = compoundA[split:]

# Split biomass array
t1 = t[:split]
t2 = t[split:]

x_train1 = [compoundA_train, substrate_train]
x_test1 = [compoundA_test, substrate_test]

# Prepare the training and test inputs
x_train = np.array(x_train1).transpose()
x_test = np.array(x_test1).transpose()

# Creating the neural network with TF
nnet = Sequential()
nnet.add(Dense(25, input_dim=2, activation='tanh'))
nnet.add(Dense(1, activation='linear'))

# Learning algorithm and learning rate
nnet.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.0001))

# Training the neural network
history = nnet.fit(x_train, t1, validation_data=(x_test, t2), batch_size=25, epochs = 100, verbose=0)

# Feedforward propagation, i.e., network output with training
yt_train = nnet.predict(x_train)
yt_test = nnet.predict(x_test)

# Plotting network output with training
i = np.arange(1, len(compoundA_train)+1)
i1 = np.arange(1, len(compoundA_test)+1)
plt.plot(i, t1, 'r*-',label='Target')
plt.plot(i, yt_train, 'k+-',label='Output')
plt.title('Network output with training data')
plt.legend()
plt.show()

plt.plot(i1, t2, 'r*-',label='Target')
plt.plot(i1, yt_test, 'k+-',label='Output')
plt.title('Network output with testing data')
plt.legend()
plt.show()
yt_train = yt_train.flatten()
yt_test = yt_test.flatten()
# Compute metrics on training data
IA_train = 1 - ((np.sum((yt_train - t1)**2)) / (np.sum((np.abs(yt_train - np.mean(t1)) + np.abs(t1 - np.mean(t1)))**2)))
rms_train = sqrt(np.sum((yt_train - t1)**2)/np.sum(yt_train ** 2))
RSD_train = sqrt((np.sum((yt_train - t1)**2)) / len(compoundA_train))
print(f"Training data: IA={IA_train}, RMS={rms_train}, RSD={RSD_train}")

# Compute metrics on testing data
IA_test = 1 - (np.sum((yt_test - t2)**2)) / (np.sum((np.abs(yt_test - np.mean(t2)) + np.abs(t2 - np.mean(t2)))**2))
rms_test = sqrt(np.sum((yt_test - t2)**2)/ np.sum(yt_test ** 2))
RSD_test = sqrt((np.sum((yt_test - t2)**2)) / len(compoundA_test))
print(f"Testing data: IA={IA_test}, RMS={rms_test}, RSD={RSD_test}")

# Plotting the training and validation loss
plt.figure(figsize=(10,5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
